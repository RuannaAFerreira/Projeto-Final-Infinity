# -*- coding: utf-8 -*-
"""PROEJTO_FINAL.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ga-1R3TJThN-67fvZy6D1KxnC_YWVQ6H
"""

#Importando as bibliotecas necessárias.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime

#Carregando o dataset a ser utilizado no estudo
df = pd.read_csv('/content/drive/MyDrive/Salvo do Chrome/walmart.csv.zip')

#Visualizando as primeiras linhas do dataset
print(df.head())

#Verificando as informações gerais do dataset/ Foi possível verificar que não há valores nulos
print(df.info())

#Reorganizando os dados e excluindo colunas de modo a facilitar sua manipulação e otimizando o uso de espaço de armazenamento.
#Convertendo colunas em categorias
df['Gender'] = df['Gender'].astype('category')
df['Age'] = df['Age'].astype('category')
df['City_Category'] = df['City_Category'].astype('category')
df['Product_ID'] = df['Product_ID'].astype('category')

#Convertendo a categoria 'Stay_In_Current_City_Years' - substituindo '4+' por 4.
df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].replace('4+', 4).astype(int)
df = df.drop(['User_ID'], axis=1)

#Verificando as informações gerais do dataset após ajustes
print(df.info())

#Entendendo as informações contidas na coluna Gênero
df['Gender'].value_counts()

#Entendendo as informações contidas na coluna Idade
df['Age'].value_counts()

#Entendendo as informações contidas na coluna Ocupação
df['Occupation'].value_counts()

#Entendendo as informações contidas na coluna Categoria de Cidades
df['City_Category'].value_counts()

#Entendendo as informações contidas na coluna Estado Civil
df['Marital_Status'].value_counts()

#Visão geral das variáveis no conjunto de dados
df.describe()

#Inciando a análise exploratória de dados

#Analisando os dados, comparando a frequência de consumo por gêneros. Conclusão: A maioria dos consumidores são do sexo masculino

plt.figure(figsize=(8, 6))
sns.countplot(x='Gender', data=df)
plt.title('Frequência de consumo por gênero')
plt.xlabel('Gênero')
plt.ylabel('Frequência de Compras')
plt.show()

#Os consumidores com maior frequência de consumo estão localizados na faixa etária de 26 a 35 anos, seguidos pelas faixas de 36 a 45 anos e 18 a 25 anos, respectivamente.

plt.figure(figsize=(8, 6))
sns.barplot(x='Age', y='Purchase', data=df)
sns.histplot(df['Age'], bins=20, kde=True)
plt.title('Frequência de consumo por faixa etária')
plt.xlabel('Faixa Etária')
plt.ylabel('Frequência de Compras')
plt.show()

#O valor das compras é um pouco maior para o sexo masculino.

plt.figure(figsize=(8,6))
sns.boxplot(x='Gender', y='Purchase', data=df)
plt.title('Distribuição do valor das compras por gênero')
plt.xlabel('Gênero')
plt.ylabel('Valor da compra')
plt.show()

#Os consumidores da cidade C tem maior frequência de compras do que as demais cidades.

plt.figure(figsize=(8, 6))
sns.barplot(x='City_Category', y='Purchase', data=df)
plt.title('Frequência de consumo por cidade')
plt.xlabel('Cidade')
plt.ylabel('Frequência de Compras')

#Relação entre as categorias dos produtos e o valor das compras

plt.figure(figsize=(10,6))
sns.scatterplot(x=df["Product_Category"], y=df["Purchase"], alpha=0.6, color="purple")
plt.title("Relação entre categoria do produto e valor da compra")
plt.xlabel("Categoria do Produto")
plt.ylabel("Valor da Compra")
plt.show()

# Selecionando somente as colunas numéricas
num_df = df.select_dtypes(include=['int64'])

#Calculando a matriz de correlação
corr_matrix = num_df.corr()

#Evidenciando a matriz de correlação
print(corr_matrix)

#Repesentação gráfica da matriz de correlação usando um mapa de calor

plt.figure(figsize=(8,6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlação entre variáveis numéricas')
plt.show()

#Verificamos que não há correlação significativas entre as variáveis numéricas do conjunto de dados

#Criando uma cópia do Dataframe para modificar a informação sobre a coluna 'Marital_Status'
df_new = df.copy()
df_new.loc[df_new['Marital_Status'] == 0, 'Marital_Status'] = 'Solteiro'
df_new.loc[df_new['Marital_Status'] == 1, 'Marital_Status'] = 'Casados/Outros'

#Representação gráfica
sns.countplot(data = df_new, x='Marital_Status',hue='Gender')
plt.title('Distribuição de gênero por estado civil e valor da compra')
plt.xlabel('Estado Civil')
plt.ylabel('Valor da Compra')

#Criando novo dataframe para evidenciação do TOP 10 dos produtos mais vendidos
top10_produtos = df['Product_ID'].value_counts().head(10).index
df_top10_produtos = df[df['Product_ID'].isin(top10_produtos)]

#Representação gráfica
plt.figure(figsize=(10,6))
sns.countplot(x='Product_ID', data=df_top10_produtos, order=top10_produtos)
plt.title('Top 10 produtos mais vendidos')

#Representação gráfica das vendas por categorias - Vendas por Ocupação
df.boxplot("Purchase", by = "Occupation")

#Representação gráfica das vendas por categorias - Vendas por Anos de permanência na cidade atual
df.boxplot("Purchase", by = "Stay_In_Current_City_Years")

#Importando bibliotecas para modelagem de Machine Learning
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import accuracy_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn import set_config
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from copy import deepcopy

#Separando as variáveis numéricas e categóricas
num_features = ['Purchase']
cat_features = ['Gender',
                'Age',
                'Occupation',
                'City_Category',
                'Stay_In_Current_City_Years',
                'Marital_Status',
                'Product_Category']

#Criando novo dataframe com as variáveis numéricas
num_features = pd.DataFrame(df['Purchase'])
num_features

#Criando novo dataframe com as varáveis categóricas
cat_features = pd.DataFrame(df[['Gender',
                'Age',
                'Occupation',
                'City_Category',
                'Stay_In_Current_City_Years',
                'Marital_Status',
                'Product_Category']])
cat_features

#Definindo as variáveis independentes (x) e a variável alvo (y)
x = cat_features
y = num_features

y.dtypes

x.dtypes

x

#Classe pré-processamento para transformar variáveis categóricas no formato mais adequado para o aprendizado de máquina

class FeatureEncoder(BaseEstimator, TransformerMixin):

    def fit(self, x, y=None):
        return self

    def transform(self, x):


        age_dct = {"0-17": 0, "18-25": 1, "26-35": 2, "36-45": 3, "46-50": 4, "51-55": 5, "55+": 6}
        x = x.copy()
        x["Age"] = x["Age"].map(age_dct)

        #Transformando variáveis categóricas em colunas binárias
        ohe = OneHotEncoder()
        matrix = ohe.fit_transform(x[["City_Category"]]).toarray()

        column_names = ["City_Cat_A", "City_Cat_B", "City_Cat_C"]

        for i in range(len(matrix.T)):
            x[column_names[i]] = matrix.T[i]

        x = x.drop(columns = ["City_Category"], axis=1)

        #Transformando variáveis categóricas em colunas binárias
        ohe = OneHotEncoder()
        matrix = ohe.fit_transform(x[["Occupation"]]).toarray()

        column_names = ["Occupation_" + str(i) for i in range(21)]

        for i in range(len(matrix.T)):
            x[column_names[i]] = matrix.T[i]

        x = x.drop(columns = ["Occupation"], axis=1)

        #Transformando variáveis categóricas em colunas binárias
        ohe = OneHotEncoder()
        matrix = ohe.fit_transform(x[["Product_Category"]]).toarray()

        column_names = ["Product_Category_" + str(i) for i in range(20)]

        for i in range(len(matrix.T)):
            x[column_names[i]] = matrix.T[i]

        x = x.drop(columns = ["Product_Category"], axis=1)

        return x

# Criando o pipeline
prepipe = Pipeline([
    ('preprocessor', FeatureEncoder()),
    ('encoder', OneHotEncoder())
])

# Fit o pipeline
x= prepipe.fit_transform(x)

#Converter x em um dataframe pandas após transformação para um array

x = pd.DataFrame(x.toarray())
x.head()

#Normalizando os dados
scaler = RobustScaler().fit(y)
y = scaler.transform(y)
y = pd.DataFrame(y)
y

#Dividindo os dados em treino e teste

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

print(X_train)

print(x_test)

#Pipeline = Regressão linear
pipeline1 = Pipeline([
    ('regressor', LinearRegression())
])
pipeline1.fit(x_train, y_train)
y_pred = pipeline1.predict(x_test)

#Avaliando o desempenho do modelo treinado
train = pipeline1.score(x_train, y_train)
print('Linear Regression on trained data: ', train)

#Avaliando o desempenho do conjunto de teste
test = pipeline1.score(x_test, y_test)
print('Linear Regression on test data: ', test)

#Pipeline - Regressão baseada na árvore de decisão
pipeline2 = Pipeline([
    ('regressor', DecisionTreeRegressor())
])
pipeline2.fit(x_train, y_train)
y_pred = pipeline2.predict(x_test)

#Avaliando o desempenho do modelo treinado
train = pipeline2.score(x_train, y_train)
print('Decision Tree Regressor on trained data: ', train)

##Avaliando o desempenho do conjunto de teste
test = pipeline2.score(x_test, y_test)
print('Decision Tree Regressor on test data: ', test)

#Avaliando o modelo de regrssão aplicado
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# resultados
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R²): {r2:.2f}")

# Importação das bibliotecas necessárias
from xgboost import XGBRegressor

# Criando uma lista de modelos
modelos = {
"Linear Regression": LinearRegression(),
"Decision Tree": DecisionTreeRegressor(max_depth=10, min_samples_split=5, min_samples_leaf=2),
"Random Forest": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),
"XGBoost": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6)
}

# Criando um dicionário para armazenar os resultados
resultados = {}

# Treinando e avaliando cada modelo
for nome, modelo in modelos.items():
  modelo.fit(x_train, y_train)
  y_pred = modelo.predict(x_test)

  # Calculando as métricas de desempenho
  mae = mean_absolute_error(y_test, y_pred)
  mse = mean_squared_error(y_test, y_pred)
  rmse = mse ** 0.5
  r2 = r2_score(y_test, y_pred)

  # Armazenando os resultados
  resultados[nome] = {"MAE": mae, "MSE": mse, "RMSE": rmse, "R²": r2}

# Convertendo os resultados para um DataFrame
df_resultados = pd.DataFrame(resultados).T

# Exibindo os resultados
print(df_resultados)

# Plotando R² Score para os modelos

plt.figure(figsize=(10, 3))
df_resultados["R²"].plot(kind="bar", color=['blue', 'orange', 'green', 'red'])
plt.title("Comparação de R² Score entre Modelos")
plt.xlabel("Modelo")
plt.ylabel("R² Score")
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()